{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS412 - Assignment 3\n",
        "## Atesam Abdullah | 2021114"
      ],
      "metadata": {
        "id": "q8D2x-vCjluD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Install Dependencies\n"
      ],
      "metadata": {
        "id": "wBLQcEi5WtVM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXY09j_rWduk",
        "outputId": "c1d6346e-dad8-4b73-e719-4300e83647a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.15.1\n",
            "TFDS version: 4.9.8\n",
            "TFRS version: v0.7.3\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.layers import StringLookup\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"TFDS version:\", tfds.__version__)\n",
        "print(\"TFRS version:\", tfrs.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Load Data & Metadata\n",
        "\n",
        "We need:\n",
        "- **movie titles** from `movielens/100k-movies` (1 682 titles)\n",
        "- **ratings** from `movielens/100k-ratings` (100 000 interactions)\n"
      ],
      "metadata": {
        "id": "BFfZV1NjgvN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load movie titles for lookup\n",
        "movies_ds = tfds.load(\n",
        "    \"movielens/100k-movies\",\n",
        "    split=\"train\"\n",
        ").map(lambda x: x[\"movie_title\"])  # yields 1 682 strings\n",
        "\n",
        "# Build movie lookup\n",
        "movie_lookup = StringLookup(mask_token=None, oov_token=\"[UNK]\")\n",
        "movie_lookup.adapt(movies_ds)\n",
        "\n",
        "# Load ratings and preprocess\n",
        "def preprocess(x):\n",
        "    return {\n",
        "        \"user_id\": tf.cast(x[\"user_id\"], tf.string),\n",
        "        \"movie_title\": x[\"movie_title\"],\n",
        "        \"rating\": tf.cast(x[\"user_rating\"], tf.float32),\n",
        "    }\n",
        "\n",
        "ratings = tfds.load(\n",
        "    \"movielens/100k-ratings\",\n",
        "    split=\"train\",\n",
        "    shuffle_files=True\n",
        ").map(preprocess)"
      ],
      "metadata": {
        "id": "h8HkSTZKgvd1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Build User Lookup & Dataset Splits\n",
        "\n",
        "- Adapt a **user** `StringLookup` on the 100 000 ratings (~943 unique IDs).  \n",
        "- Shuffle & split 80 % train / 20 % test.  \n",
        "- Batch & cache.\n"
      ],
      "metadata": {
        "id": "-YfvTcKrg5X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User lookup\n",
        "user_lookup = StringLookup(mask_token=None, oov_token=\"[UNK]\")\n",
        "user_lookup.adapt(ratings.map(lambda x: x[\"user_id\"]))\n",
        "\n",
        "# Inspect vocab sizes\n",
        "num_users  = user_lookup.vocabulary_size()\n",
        "num_movies = movie_lookup.vocabulary_size()\n",
        "print(f\"Users: {num_users}, Movies: {num_movies}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np1szjPHg5_X",
        "outputId": "e318ed00-f784-440d-b6b6-02a6979dada8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Users: 944, Movies: 1665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Shuffle & split\n"
      ],
      "metadata": {
        "id": "TgtBmWyLhHpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(80_000).batch(4096).cache()\n",
        "test  = shuffled.skip(80_000).batch(2048).cache()"
      ],
      "metadata": {
        "id": "R5qHgE-khGU6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Define the MLP Model\n",
        "\n",
        "- Embed user & movie, concatenate, pass through dense layers → predict rating.\n"
      ],
      "metadata": {
        "id": "rbEfsxwPhPFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  class MLPModel(tf.keras.Model):\n",
        "    def __init__(self, user_vocab_size, movie_vocab_size, embedding_dim=32, hidden_units=[64,32]):\n",
        "        super().__init__()\n",
        "        self.user_emb = layers.Embedding(user_vocab_size, embedding_dim)\n",
        "        self.movie_emb = layers.Embedding(movie_vocab_size, embedding_dim)\n",
        "        self.mlp = tf.keras.Sequential([\n",
        "            layers.Dense(units, activation=\"relu\") for units in hidden_units\n",
        "        ] + [layers.Dense(1)])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        u, m = inputs\n",
        "        u_vec = self.user_emb(u)\n",
        "        m_vec = self.movie_emb(m)\n",
        "        x = tf.concat([u_vec, m_vec], axis=1)\n",
        "        return self.mlp(x)\n",
        "\n",
        "class MLPRecommender(tfrs.models.Model):\n",
        "    def __init__(self, user_vocab_size, movie_vocab_size):\n",
        "        super().__init__()\n",
        "        self.model = MLPModel(user_vocab_size, movie_vocab_size)\n",
        "        self.task = tfrs.tasks.Ranking(\n",
        "            loss=tf.keras.losses.MeanSquaredError(),\n",
        "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")]\n",
        "        )\n",
        "\n",
        "    def call(self, features):\n",
        "        # apply lookups\n",
        "        u = user_lookup(features[\"user_id\"])\n",
        "        m = movie_lookup(features[\"movie_title\"])\n",
        "        return self.model((u, m))\n",
        "\n",
        "    def compute_loss(self, features, training=False):\n",
        "        labels = features.pop(\"rating\")\n",
        "        preds  = self(features)\n",
        "        return self.task(labels=labels, predictions=preds)"
      ],
      "metadata": {
        "id": "MFiBQKnphSoV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 Define the NeuMF Model\n",
        "\n",
        "- Two paths: GMF (element-wise product) + MLP → merge → predict.\n"
      ],
      "metadata": {
        "id": "Tmh1aYIxhVJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuMFModel(tf.keras.Model):\n",
        "    def __init__(self, user_vocab_size, movie_vocab_size, embedding_dim=32, mlp_units=[64,32]):\n",
        "        super().__init__()\n",
        "        # GMF path\n",
        "        self.gmf_user = layers.Embedding(user_vocab_size, embedding_dim)\n",
        "        self.gmf_movie = layers.Embedding(movie_vocab_size, embedding_dim)\n",
        "        # MLP path\n",
        "        self.mlp_user = layers.Embedding(user_vocab_size, embedding_dim)\n",
        "        self.mlp_movie = layers.Embedding(movie_vocab_size, embedding_dim)\n",
        "        self.mlp = tf.keras.Sequential([\n",
        "            layers.Dense(u, activation=\"relu\") for u in mlp_units\n",
        "        ])\n",
        "        # Final prediction\n",
        "        self.out = layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        u_id, m_id = inputs\n",
        "        # GMF\n",
        "        g = self.gmf_user(u_id) * self.gmf_movie(m_id)\n",
        "        # MLP\n",
        "        concat = tf.concat([self.mlp_user(u_id), self.mlp_movie(m_id)], axis=1)\n",
        "        mlp_out = self.mlp(concat)\n",
        "        # Merge\n",
        "        x = tf.concat([g, mlp_out], axis=1)\n",
        "        return self.out(x)\n",
        "\n",
        "class NeuMFRecommender(tfrs.models.Model):\n",
        "    def __init__(self, user_vocab_size, movie_vocab_size):\n",
        "        super().__init__()\n",
        "        self.model = NeuMFModel(user_vocab_size, movie_vocab_size)\n",
        "        self.task = tfrs.tasks.Ranking(\n",
        "            loss=tf.keras.losses.MeanSquaredError(),\n",
        "            metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")]\n",
        "        )\n",
        "\n",
        "    def call(self, features):\n",
        "        u = user_lookup(features[\"user_id\"])\n",
        "        m = movie_lookup(features[\"movie_title\"])\n",
        "        return self.model((u, m))\n",
        "\n",
        "    def compute_loss(self, features, training=False):\n",
        "        labels = features.pop(\"rating\")\n",
        "        preds  = self(features)\n",
        "        return self.task(labels=labels, predictions=preds)"
      ],
      "metadata": {
        "id": "apsZ_8-DhVh8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 Compile & Train\n",
        "\n",
        "Train each model for 15 epochs.\n"
      ],
      "metadata": {
        "id": "8w4BpCEdhd9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.1 MLP\n",
        "# Instantiate and compile the MLP recommender\n",
        "mlp = MLPRecommender(num_users, num_movies)\n",
        "mlp.compile(\n",
        "    optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1),\n",
        "    metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")]\n",
        ")\n",
        "\n",
        "print(\"▶️ Starting training: MLP model (25 epochs)...\")\n",
        "history_mlp = mlp.fit(\n",
        "    train,\n",
        "    validation_data=test,\n",
        "    epochs=25,\n",
        "    verbose=2  # show one line per epoch\n",
        ")\n",
        "print(\"✅ Finished training: MLP model!\")\n",
        "\n",
        "# 7.2 NeuMF\n",
        "# Instantiate and compile the NeuMF recommender\n",
        "nemf = NeuMFRecommender(num_users, num_movies)\n",
        "nemf.compile(\n",
        "    optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1),\n",
        "    metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")]\n",
        ")\n",
        "\n",
        "print(\"▶️ Starting training: NeuMF model (25 epochs)...\")\n",
        "history_nemf = nemf.fit(\n",
        "    train,\n",
        "    validation_data=test,\n",
        "    epochs=25,\n",
        "    verbose=2\n",
        ")\n",
        "print(\"✅ Finished training: NeuMF model!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcBd1ruKhfeY",
        "outputId": "a7184c67-3488-44bc-a5fa-14c045deb76a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ Starting training: MLP model (25 epochs)...\n",
            "Epoch 1/25\n",
            "20/20 - 1s - rmse: 1.5641 - loss: 1.1718 - regularization_loss: 0.0000e+00 - total_loss: 1.1718 - val_rmse: 1.0965 - val_loss: 1.2004 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2004 - 843ms/epoch - 42ms/step\n",
            "Epoch 2/25\n",
            "20/20 - 0s - rmse: 1.0792 - loss: 1.0658 - regularization_loss: 0.0000e+00 - total_loss: 1.0658 - val_rmse: 1.0479 - val_loss: 1.0927 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.0927 - 214ms/epoch - 11ms/step\n",
            "Epoch 3/25\n",
            "20/20 - 0s - rmse: 1.0302 - loss: 0.9666 - regularization_loss: 0.0000e+00 - total_loss: 0.9666 - val_rmse: 0.9980 - val_loss: 0.9977 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9977 - 215ms/epoch - 11ms/step\n",
            "Epoch 4/25\n",
            "20/20 - 0s - rmse: 0.9830 - loss: 0.9144 - regularization_loss: 0.0000e+00 - total_loss: 0.9144 - val_rmse: 0.9723 - val_loss: 0.9505 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9505 - 193ms/epoch - 10ms/step\n",
            "Epoch 5/25\n",
            "20/20 - 0s - rmse: 0.9620 - loss: 0.8866 - regularization_loss: 0.0000e+00 - total_loss: 0.8866 - val_rmse: 0.9599 - val_loss: 0.9282 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9282 - 209ms/epoch - 10ms/step\n",
            "Epoch 6/25\n",
            "20/20 - 0s - rmse: 0.9506 - loss: 0.8686 - regularization_loss: 0.0000e+00 - total_loss: 0.8686 - val_rmse: 0.9518 - val_loss: 0.9144 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9144 - 176ms/epoch - 9ms/step\n",
            "Epoch 7/25\n",
            "20/20 - 0s - rmse: 0.9417 - loss: 0.8567 - regularization_loss: 0.0000e+00 - total_loss: 0.8567 - val_rmse: 0.9465 - val_loss: 0.9057 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9057 - 173ms/epoch - 9ms/step\n",
            "Epoch 8/25\n",
            "20/20 - 0s - rmse: 0.9357 - loss: 0.8490 - regularization_loss: 0.0000e+00 - total_loss: 0.8490 - val_rmse: 0.9434 - val_loss: 0.9008 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9008 - 216ms/epoch - 11ms/step\n",
            "Epoch 9/25\n",
            "20/20 - 0s - rmse: 0.9322 - loss: 0.8434 - regularization_loss: 0.0000e+00 - total_loss: 0.8434 - val_rmse: 0.9415 - val_loss: 0.8978 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8978 - 197ms/epoch - 10ms/step\n",
            "Epoch 10/25\n",
            "20/20 - 0s - rmse: 0.9298 - loss: 0.8393 - regularization_loss: 0.0000e+00 - total_loss: 0.8393 - val_rmse: 0.9402 - val_loss: 0.8958 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8958 - 173ms/epoch - 9ms/step\n",
            "Epoch 11/25\n",
            "20/20 - 0s - rmse: 0.9280 - loss: 0.8363 - regularization_loss: 0.0000e+00 - total_loss: 0.8363 - val_rmse: 0.9393 - val_loss: 0.8945 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8945 - 176ms/epoch - 9ms/step\n",
            "Epoch 12/25\n",
            "20/20 - 0s - rmse: 0.9264 - loss: 0.8341 - regularization_loss: 0.0000e+00 - total_loss: 0.8341 - val_rmse: 0.9387 - val_loss: 0.8935 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8935 - 174ms/epoch - 9ms/step\n",
            "Epoch 13/25\n",
            "20/20 - 0s - rmse: 0.9253 - loss: 0.8323 - regularization_loss: 0.0000e+00 - total_loss: 0.8323 - val_rmse: 0.9382 - val_loss: 0.8928 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8928 - 237ms/epoch - 12ms/step\n",
            "Epoch 14/25\n",
            "20/20 - 0s - rmse: 0.9244 - loss: 0.8309 - regularization_loss: 0.0000e+00 - total_loss: 0.8309 - val_rmse: 0.9379 - val_loss: 0.8923 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8923 - 178ms/epoch - 9ms/step\n",
            "Epoch 15/25\n",
            "20/20 - 0s - rmse: 0.9236 - loss: 0.8297 - regularization_loss: 0.0000e+00 - total_loss: 0.8297 - val_rmse: 0.9376 - val_loss: 0.8919 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8919 - 174ms/epoch - 9ms/step\n",
            "Epoch 16/25\n",
            "20/20 - 0s - rmse: 0.9230 - loss: 0.8288 - regularization_loss: 0.0000e+00 - total_loss: 0.8288 - val_rmse: 0.9374 - val_loss: 0.8915 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8915 - 174ms/epoch - 9ms/step\n",
            "Epoch 17/25\n",
            "20/20 - 0s - rmse: 0.9225 - loss: 0.8279 - regularization_loss: 0.0000e+00 - total_loss: 0.8279 - val_rmse: 0.9373 - val_loss: 0.8911 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8911 - 214ms/epoch - 11ms/step\n",
            "Epoch 18/25\n",
            "20/20 - 0s - rmse: 0.9221 - loss: 0.8272 - regularization_loss: 0.0000e+00 - total_loss: 0.8272 - val_rmse: 0.9372 - val_loss: 0.8909 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8909 - 227ms/epoch - 11ms/step\n",
            "Epoch 19/25\n",
            "20/20 - 0s - rmse: 0.9217 - loss: 0.8265 - regularization_loss: 0.0000e+00 - total_loss: 0.8265 - val_rmse: 0.9371 - val_loss: 0.8906 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8906 - 174ms/epoch - 9ms/step\n",
            "Epoch 20/25\n",
            "20/20 - 0s - rmse: 0.9214 - loss: 0.8259 - regularization_loss: 0.0000e+00 - total_loss: 0.8259 - val_rmse: 0.9370 - val_loss: 0.8903 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8903 - 172ms/epoch - 9ms/step\n",
            "Epoch 21/25\n",
            "20/20 - 0s - rmse: 0.9211 - loss: 0.8254 - regularization_loss: 0.0000e+00 - total_loss: 0.8254 - val_rmse: 0.9369 - val_loss: 0.8901 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8901 - 176ms/epoch - 9ms/step\n",
            "Epoch 22/25\n",
            "20/20 - 0s - rmse: 0.9208 - loss: 0.8249 - regularization_loss: 0.0000e+00 - total_loss: 0.8249 - val_rmse: 0.9369 - val_loss: 0.8898 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8898 - 237ms/epoch - 12ms/step\n",
            "Epoch 23/25\n",
            "20/20 - 0s - rmse: 0.9206 - loss: 0.8244 - regularization_loss: 0.0000e+00 - total_loss: 0.8244 - val_rmse: 0.9368 - val_loss: 0.8897 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8897 - 171ms/epoch - 9ms/step\n",
            "Epoch 24/25\n",
            "20/20 - 0s - rmse: 0.9204 - loss: 0.8239 - regularization_loss: 0.0000e+00 - total_loss: 0.8239 - val_rmse: 0.9368 - val_loss: 0.8895 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8895 - 213ms/epoch - 11ms/step\n",
            "Epoch 25/25\n",
            "20/20 - 0s - rmse: 0.9201 - loss: 0.8235 - regularization_loss: 0.0000e+00 - total_loss: 0.8235 - val_rmse: 0.9368 - val_loss: 0.8893 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8893 - 213ms/epoch - 11ms/step\n",
            "✅ Finished training: MLP model!\n",
            "▶️ Starting training: NeuMF model (25 epochs)...\n",
            "Epoch 1/25\n",
            "20/20 - 1s - rmse: 1.6533 - loss: 1.1763 - regularization_loss: 0.0000e+00 - total_loss: 1.1763 - val_rmse: 1.0948 - val_loss: 1.1877 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.1877 - 1s/epoch - 72ms/step\n",
            "Epoch 2/25\n",
            "20/20 - 0s - rmse: 1.0753 - loss: 1.0815 - regularization_loss: 0.0000e+00 - total_loss: 1.0815 - val_rmse: 1.0469 - val_loss: 1.0961 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.0961 - 362ms/epoch - 18ms/step\n",
            "Epoch 3/25\n",
            "20/20 - 0s - rmse: 1.0237 - loss: 0.9891 - regularization_loss: 0.0000e+00 - total_loss: 0.9891 - val_rmse: 1.0024 - val_loss: 1.0096 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.0096 - 376ms/epoch - 19ms/step\n",
            "Epoch 4/25\n",
            "20/20 - 0s - rmse: 0.9889 - loss: 0.9376 - regularization_loss: 0.0000e+00 - total_loss: 0.9376 - val_rmse: 0.9811 - val_loss: 0.9643 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9643 - 208ms/epoch - 10ms/step\n",
            "Epoch 5/25\n",
            "20/20 - 0s - rmse: 0.9748 - loss: 0.9020 - regularization_loss: 0.0000e+00 - total_loss: 0.9020 - val_rmse: 0.9647 - val_loss: 0.9358 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9358 - 205ms/epoch - 10ms/step\n",
            "Epoch 6/25\n",
            "20/20 - 0s - rmse: 0.9540 - loss: 0.8789 - regularization_loss: 0.0000e+00 - total_loss: 0.8789 - val_rmse: 0.9541 - val_loss: 0.9189 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9189 - 273ms/epoch - 14ms/step\n",
            "Epoch 7/25\n",
            "20/20 - 0s - rmse: 0.9438 - loss: 0.8651 - regularization_loss: 0.0000e+00 - total_loss: 0.8651 - val_rmse: 0.9486 - val_loss: 0.9097 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9097 - 200ms/epoch - 10ms/step\n",
            "Epoch 8/25\n",
            "20/20 - 0s - rmse: 0.9383 - loss: 0.8553 - regularization_loss: 0.0000e+00 - total_loss: 0.8553 - val_rmse: 0.9451 - val_loss: 0.9037 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9037 - 236ms/epoch - 12ms/step\n",
            "Epoch 9/25\n",
            "20/20 - 0s - rmse: 0.9347 - loss: 0.8482 - regularization_loss: 0.0000e+00 - total_loss: 0.8482 - val_rmse: 0.9427 - val_loss: 0.8999 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8999 - 205ms/epoch - 10ms/step\n",
            "Epoch 10/25\n",
            "20/20 - 0s - rmse: 0.9317 - loss: 0.8431 - regularization_loss: 0.0000e+00 - total_loss: 0.8431 - val_rmse: 0.9408 - val_loss: 0.8975 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8975 - 240ms/epoch - 12ms/step\n",
            "Epoch 11/25\n",
            "20/20 - 0s - rmse: 0.9292 - loss: 0.8394 - regularization_loss: 0.0000e+00 - total_loss: 0.8394 - val_rmse: 0.9395 - val_loss: 0.8958 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8958 - 204ms/epoch - 10ms/step\n",
            "Epoch 12/25\n",
            "20/20 - 0s - rmse: 0.9273 - loss: 0.8366 - regularization_loss: 0.0000e+00 - total_loss: 0.8366 - val_rmse: 0.9386 - val_loss: 0.8947 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8947 - 206ms/epoch - 10ms/step\n",
            "Epoch 13/25\n",
            "20/20 - 0s - rmse: 0.9259 - loss: 0.8343 - regularization_loss: 0.0000e+00 - total_loss: 0.8343 - val_rmse: 0.9380 - val_loss: 0.8939 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8939 - 205ms/epoch - 10ms/step\n",
            "Epoch 14/25\n",
            "20/20 - 0s - rmse: 0.9248 - loss: 0.8324 - regularization_loss: 0.0000e+00 - total_loss: 0.8324 - val_rmse: 0.9375 - val_loss: 0.8932 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8932 - 205ms/epoch - 10ms/step\n",
            "Epoch 15/25\n",
            "20/20 - 0s - rmse: 0.9239 - loss: 0.8308 - regularization_loss: 0.0000e+00 - total_loss: 0.8308 - val_rmse: 0.9371 - val_loss: 0.8926 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8926 - 253ms/epoch - 13ms/step\n",
            "Epoch 16/25\n",
            "20/20 - 0s - rmse: 0.9231 - loss: 0.8295 - regularization_loss: 0.0000e+00 - total_loss: 0.8295 - val_rmse: 0.9368 - val_loss: 0.8921 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8921 - 204ms/epoch - 10ms/step\n",
            "Epoch 17/25\n",
            "20/20 - 0s - rmse: 0.9225 - loss: 0.8284 - regularization_loss: 0.0000e+00 - total_loss: 0.8284 - val_rmse: 0.9366 - val_loss: 0.8916 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8916 - 203ms/epoch - 10ms/step\n",
            "Epoch 18/25\n",
            "20/20 - 0s - rmse: 0.9220 - loss: 0.8274 - regularization_loss: 0.0000e+00 - total_loss: 0.8274 - val_rmse: 0.9364 - val_loss: 0.8913 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8913 - 203ms/epoch - 10ms/step\n",
            "Epoch 19/25\n",
            "20/20 - 0s - rmse: 0.9215 - loss: 0.8264 - regularization_loss: 0.0000e+00 - total_loss: 0.8264 - val_rmse: 0.9363 - val_loss: 0.8911 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8911 - 257ms/epoch - 13ms/step\n",
            "Epoch 20/25\n",
            "20/20 - 0s - rmse: 0.9210 - loss: 0.8256 - regularization_loss: 0.0000e+00 - total_loss: 0.8256 - val_rmse: 0.9362 - val_loss: 0.8909 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8909 - 204ms/epoch - 10ms/step\n",
            "Epoch 21/25\n",
            "20/20 - 0s - rmse: 0.9207 - loss: 0.8248 - regularization_loss: 0.0000e+00 - total_loss: 0.8248 - val_rmse: 0.9361 - val_loss: 0.8907 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8907 - 208ms/epoch - 10ms/step\n",
            "Epoch 22/25\n",
            "20/20 - 0s - rmse: 0.9204 - loss: 0.8242 - regularization_loss: 0.0000e+00 - total_loss: 0.8242 - val_rmse: 0.9360 - val_loss: 0.8905 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8905 - 202ms/epoch - 10ms/step\n",
            "Epoch 23/25\n",
            "20/20 - 0s - rmse: 0.9201 - loss: 0.8236 - regularization_loss: 0.0000e+00 - total_loss: 0.8236 - val_rmse: 0.9360 - val_loss: 0.8903 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8903 - 228ms/epoch - 11ms/step\n",
            "Epoch 24/25\n",
            "20/20 - 0s - rmse: 0.9198 - loss: 0.8230 - regularization_loss: 0.0000e+00 - total_loss: 0.8230 - val_rmse: 0.9359 - val_loss: 0.8901 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8901 - 206ms/epoch - 10ms/step\n",
            "Epoch 25/25\n",
            "20/20 - 0s - rmse: 0.9196 - loss: 0.8225 - regularization_loss: 0.0000e+00 - total_loss: 0.8225 - val_rmse: 0.9359 - val_loss: 0.8899 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8899 - 207ms/epoch - 10ms/step\n",
            "✅ Finished training: NeuMF model!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8 Evaluate & Compare Models\n",
        "\n",
        "In this step we:\n",
        "\n",
        "1. Compute the **RMSE** on the test set for both models.  \n",
        "2. Print out the metrics side by side.  \n",
        "3. Summarize which model performs better.\n"
      ],
      "metadata": {
        "id": "zfjrKi6PhlZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8.1 Evaluate on test set\n",
        "mlp_results = mlp.evaluate(test, return_dict=True, verbose=0)\n",
        "nemf_results = nemf.evaluate(test, return_dict=True, verbose=0)\n",
        "\n",
        "# 8.2 Extract RMSE values\n",
        "mlp_rmse  = mlp_results[\"rmse\"]\n",
        "nemf_rmse = nemf_results[\"rmse\"]\n",
        "\n",
        "# 8.3 Display raw outputs\n",
        "print(f\"MLP Evaluation Results:\\n  Loss = {mlp_results['loss']:.4f}\\n  RMSE = {mlp_rmse:.4f}\\n\")\n",
        "print(f\"NeuMF Evaluation Results:\\n  Loss = {nemf_results['loss']:.4f}\\n  RMSE = {nemf_rmse:.4f}\\n\")\n",
        "\n",
        "# 8.4 Compare side by side\n",
        "if mlp_rmse < nemf_rmse:\n",
        "    better = \"MLP\"\n",
        "    improvement = (nemf_rmse - mlp_rmse) / nemf_rmse * 100\n",
        "else:\n",
        "    better = \"NeuMF\"\n",
        "    improvement = (mlp_rmse - nemf_rmse) / mlp_rmse * 100\n",
        "\n",
        "print(\"📝 Comparison:\")\n",
        "print(f\"  → {better} achieves the lower RMSE.\")\n",
        "print(f\"  → Improvement: {abs(improvement):.2f}% relative reduction in RMSE.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJqT1DwAhm2Z",
        "outputId": "27ecc4ec-24d7-4f6a-d822-2ce6682f32a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Evaluation Results:\n",
            "  Loss = 0.8893\n",
            "  RMSE = 0.9368\n",
            "\n",
            "NeuMF Evaluation Results:\n",
            "  Loss = 0.8899\n",
            "  RMSE = 0.9359\n",
            "\n",
            "📝 Comparison:\n",
            "  → NeuMF achieves the lower RMSE.\n",
            "  → Improvement: 0.09% relative reduction in RMSE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{'User':<6} {'Movie':<40} {'Actual':<6} {'MLP Pred':<8} {'NeuMF Pred':<10}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Unbatch the test set, take first 10 examples\n",
        "for example in test.unbatch().take(10):\n",
        "    user = example['user_id']\n",
        "    movie = example['movie_title']\n",
        "    actual = example['rating'].numpy()\n",
        "\n",
        "    # Wrap into a batch of size 1 for prediction\n",
        "    features = {\n",
        "        \"user_id\": tf.expand_dims(user, 0),\n",
        "        \"movie_title\": tf.expand_dims(movie, 0),\n",
        "    }\n",
        "\n",
        "    pred_mlp  = mlp(features).numpy()[0][0]\n",
        "    pred_nemf = nemf(features).numpy()[0][0]\n",
        "\n",
        "    print(f\"{user.numpy().decode():<6} \"\n",
        "          f\"{movie.numpy().decode():<40} \"\n",
        "          f\"{actual:<6.1f} \"\n",
        "          f\"{pred_mlp:<8.2f} \"\n",
        "          f\"{pred_nemf:<10.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1ibk2umjPIR",
        "outputId": "0284b36f-47f5-485e-d832-a3806e549cf4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User   Movie                                    Actual MLP Pred NeuMF Pred\n",
            "--------------------------------------------------------------------------------\n",
            "346    M*A*S*H (1970)                           4.0    3.79     3.79      \n",
            "602    Volcano (1997)                           4.0    3.32     3.31      \n",
            "393    2001: A Space Odyssey (1968)             1.0    4.11     4.12      \n",
            "152    Dances with Wolves (1990)                5.0    4.69     4.71      \n",
            "738    Speed (1994)                             3.0    3.63     3.62      \n",
            "382    Swingers (1996)                          2.0    3.71     3.72      \n",
            "85     Casablanca (1942)                        5.0    4.24     4.25      \n",
            "152    Independence Day (ID4) (1996)            5.0    4.25     4.25      \n",
            "186    Hoodlum (1997)                           3.0    2.99     2.99      \n",
            "130    Renaissance Man (1994)                   4.0    3.62     3.63      \n"
          ]
        }
      ]
    }
  ]
}